{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0dc64db-868e-464c-8f3a-7d8a138e563b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "library(tidyverse)\n",
    "library(dplyr)\n",
    "library(rpart)\n",
    "source('functions.R')\n",
    "library(rpart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e33c6c28-94d3-4517-b702-cf44c4026443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load the data\n",
    "train = readRDS(\"04a-wrangledTrain.rds\")\n",
    "holdout = readRDS('04b-wrangledHoldout.rds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9ccf9-a703-43cc-a1fd-b4b3f0a38eca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 05c Trees\n",
    "This file will perform k-fold cv on two different tree based models, one on the entire predictor set, the other on a subset of the predictor variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71847efa-141b-4247-8da8-e3c96751eac5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tree based functions\n",
    "Below you will find the functions FindUniquePos and kFoldTree.\n",
    "FindUniquePos finds the unique position of an element and is necessary to evaluate the interval score and coverage of tree models.\n",
    "kFoldTree is a function which performs k fold cross-validation on a tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43d4b19c-cdbc-4152-8cf3-c843a8b133e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#' @description\n",
    "#' Find group position for each element of a vector\n",
    "#'\n",
    "#' @param values vector which should values that depends on the group\n",
    "#' @param groupValues group values in the vector (hopefully unique)\n",
    "#' @param tolerance for matching equality\n",
    "#'\n",
    "#' @return group vector with membership label for each element of 'values' #'\n",
    "FindUniquePos = function(values, groupValues, tolerance=1.e-5){\n",
    "    ngroup = length(groupValues) # number of groups (terminal nodes)\n",
    "    temp = unique(groupValues)\n",
    "    if(length(temp)<ngroup){\n",
    "        cat(\"Won't work: non-unique group values\\n\"); return(0); }\n",
    "    npred = length(values) # number of cases to bin into a group label group = rep(0,npred) # initialize as group 0\n",
    "    group = rep(0,npred)\n",
    "    for(ig in 1:ngroup){\n",
    "        # group[values==groupValues[i]]=i # better to use tolerance\n",
    "        igroup = (abs(values-groupValues[ig])<tolerance)\n",
    "        group[igroup] = ig  # group label according to position in groupValues \n",
    "    }\n",
    "    if( any(group==0) ) cat(\"Warning: some values not matched to groupValues\\n\")\n",
    "    return(group)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de4b089-75fd-40ee-80ba-3ad44f02af33",
   "metadata": {},
   "source": [
    "The standard kfold function needs to be modified to allow for the interval scores generated by trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75a4fe46-7e74-4173-8396-4b1355e8fc54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#' @description\n",
    "#' Perform Kfold CV on a regression tree\n",
    "#'\n",
    "#' @param Kfold integer, the number of folds to perform kfold cv over\n",
    "#' @param seed integer, a number to set randomness for reproduction\n",
    "#' @param datafr, a dataframe to train and test the model on, all predictor variables will be used and price will be predicted\n",
    "#'\n",
    "#' @return outTree, a report of the performance of the tree on each fold\n",
    "\n",
    "kFoldTree = function(Kfold, seed, datafr)\n",
    "{ set.seed(seed)\n",
    "  n = nrow(datafr)\n",
    "  iperm<<-sample(n) # set as global for debugging check\n",
    "  nhold = round(n/Kfold)\n",
    "  reg = list()\n",
    "  pred = list() \n",
    "  scoreVar = list()\n",
    "  rocVar = list()\n",
    "  pred_y = sample(n-nhold)\n",
    "  results = data.frame(NA,nrow = 3,ncol = 4)\n",
    " \n",
    "  for(k in 1:Kfold){\n",
    "        ilow = (k-1)*nhold+1\n",
    "        ihigh = k*nhold\n",
    "        if(k==Kfold) { ihigh = n }\n",
    "        ifold = iperm[ilow:ihigh]\n",
    "        holdo = datafr[ifold,]\n",
    "        train = datafr[-ifold,]\n",
    "        RegTree = rpart(log(price)~., data=train)\n",
    "        meanByTNode = tapply(log(train$price), RegTree$where, mean)\n",
    "        Q25ByTNode = tapply(log(train$price), RegTree$where, quantile,prob=0.25)\n",
    "        Q50ByTNode = tapply(log(train$price), RegTree$where, median)\n",
    "        Q75ByTNode = tapply(log(train$price), RegTree$where, quantile,prob=0.75)\n",
    "        Q10ByTNode = tapply(log(train$price), RegTree$where, quantile, prob=0.10)\n",
    "        Q90ByTNode = tapply(log(train$price), RegTree$where, quantile, prob=0.90)\n",
    "        meanpredRegTree = predict(RegTree, newdata=holdo,type=\"vector\")\n",
    "        TNodeGroup = FindUniquePos(meanpredRegTree,meanByTNode)\n",
    "      \n",
    "        TNodeGroup = FindUniquePos(meanpredRegTree,meanByTNode)\n",
    "      \n",
    "        Q25predRegTree = Q25ByTNode[TNodeGroup]; Q75predRegTree = Q75ByTNode[TNodeGroup]\n",
    "        pred50IntRegTree = exp(cbind(meanpredRegTree,Q25predRegTree,Q75predRegTree))\n",
    "      \n",
    "        Q10predRegTree = Q10ByTNode[TNodeGroup]; Q90predRegTree = Q90ByTNode[TNodeGroup] \n",
    "        pred80IntRegTree = exp(cbind(meanpredRegTree,Q10predRegTree,Q90predRegTree))\n",
    "          \n",
    "        ISTree50 = intervalScore(pred50IntRegTree,holdo$price,0.5)\n",
    "        ISTree80 = intervalScore(pred80IntRegTree,holdo$price,0.8)\n",
    "        outTree = rbind(ISTree50$summary,ISTree80$summary)\n",
    "        colnames(outTree)=c(\"level\",\"avgleng\",\"IS\",\"cover\") \n",
    "        print(outTree)\n",
    "\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4271b-32a2-4868-91f1-bb5383708d1a",
   "metadata": {},
   "source": [
    "### Comparing the Tree\n",
    "Here I take a subset of the data to isolate the variables which we want to use as predictors to compare with other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f219cca-0b4d-430e-bb18-842993794667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     level   avgleng       IS     cover\n",
      "[1,]   0.5  9477.828 21119.11 0.5004229\n",
      "[2,]   0.8 20321.567 31628.91 0.7993725\n",
      "     level   avgleng       IS     cover\n",
      "[1,]   0.5  9795.193 21610.06 0.4985774\n",
      "[2,]   0.8 20545.379 32405.93 0.8009874\n",
      "     level   avgleng       IS     cover\n",
      "[1,]   0.5  9473.537 21142.21 0.4991541\n",
      "[2,]   0.8 19925.459 31877.84 0.7981760\n"
     ]
    }
   ],
   "source": [
    "kFoldTree(3,123,datafr = train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a1047c-3153-4628-89c8-885c17e8b650",
   "metadata": {},
   "source": [
    "This version uses the feature selection function which isolates the predictors age, fuel, drive, type, countryOrigin (manufacturer's home country), isLuxury (luxury brand indicator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85aab181-53ac-487f-922a-c07c4bf92136",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     level   avgleng       IS     cover\n",
      "[1,]   0.5  9620.351 21276.12 0.5020686\n",
      "[2,]   0.8 20199.253 31864.82 0.7985420\n",
      "     level   avgleng       IS     cover\n",
      "[1,]   0.5  9320.868 21214.83 0.4993617\n",
      "[2,]   0.8 20164.808 31920.39 0.8020486\n",
      "     level  avgleng       IS     cover\n",
      "[1,]   0.5  9623.15 21769.10 0.4988773\n",
      "[2,]   0.8 20584.09 32659.14 0.7968841\n"
     ]
    }
   ],
   "source": [
    "sub_train = feature_selection(train)\n",
    "kFoldTree(3,123,datafr = sub_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aca93e-3b1e-4c2e-b59c-82ba8d161f08",
   "metadata": {},
   "source": [
    "### Training the models\n",
    "Here we train the models and save them for comparison with other methods on the holdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87d78e4f-8952-4cfc-bd33-f12b05a5e71f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree = rpart(log(price)~., data=train)\n",
    "subsetTree = rpart(log(price)~., data=feature_selection(train))\n",
    "saveRDS(tree, \"05c-tree.rds\")\n",
    "saveRDS(subsetTree, \"05c-subsetTree.rds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
